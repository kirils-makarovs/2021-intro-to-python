{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python_Day_3_solutions.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1J_VwH0BZl_NnrWBHnK-cScNcjzQWZXEG","authorship_tag":"ABX9TyNuqRf8Hop50JrShvPaB3o/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EWB457PFT4J2"},"source":["# **Introduction to Python. Day 3**\n","\n","## *Dr Kirils Makarovs*\n","\n","## *k.makarovs@exeter.ac.uk*\n","\n","## *University of Exeter Q-Step Centre*\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"6b_C8WzNqV4z"},"source":["# **Welcome to Day 3!**"]},{"cell_type":"markdown","metadata":{"id":"ZSbdhnpgS34g"},"source":["## **By now, you should be familiar with:**\n","\n","+ The overall workflow of Jupyter Notebooks in Google Colab\n","+ The basics of Python syntax and operations with lists\n","+ How to read in external datasets\n","+ How to navigate datasets - subsetting, accessing rows/columns\n","+ Operations with variables i.e. recoding, creating new variables\n"]},{"cell_type":"markdown","metadata":{"id":"DmD95g7Na2wJ"},"source":["## **Today, we are going to look at the exploratory data analysis, i.e.:**\n","\n","+ Frequency tables, crosstabs\n","+ Descriptive statistics for numeric variables\n","+ Aggregated statistics\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlyQaFb3PFbh"},"source":["# **1. Preparing to work in Python**"]},{"cell_type":"code","metadata":{"id":"Gi-tODR_pzmZ"},"source":["# Import the necessary libraries\n","\n","import pandas as pd # data analysis and management library\n","import numpy as np # multi-dimensional arrays\n","import math # library with math-related commands like square root, etc.\n","import random # random number generator via random.sample()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XOVOH_1qrIB"},"source":["# Mount your Google Drive\n","\n","# Mounting your Google Drive will enable you to access files from Drive in Google Colab e.g. datasets, notebooks, etc.\n","\n","from google.colab import drive\n","\n","# This will prompt for authorization. Enter your authorization code and rerun the cell\n","\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0v-bTFoUpSkG"},"source":["---\n","\n","# **2. Random helpful commands**\n","\n"]},{"cell_type":"code","metadata":{"id":"Lvjr1gByp2nr"},"source":["# Getting help for Python commands\n","\n","# There are several ways to look up the meaning of pandas/numpy functions and methods, as well to see their arguments\n","\n","# 1) Google it (seriously)\n","# 2) Type and run '? <your command here>' e.g. ? pd.read_csv\n","# 3) Start typing the command and then hover the mouse over it\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRFIYjOxtK47"},"source":["# Let's create a tiny dataset\n","\n","df = pd.DataFrame(data = {'col1' : [1,2,3],\n","                          'col2' : [4,5,6],\n","                          'col3' : [7,8,9],\n","                          'col4' : [10,11,12]})\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMt06FzjrVng"},"source":["# Renaming the variables (or rows)\n","\n","# you can rename column or rows with pandas .rename() method\n","\n","df.rename(columns = {'col1' : 'column_1',\n","                     'col2' : 'column_2'}) # old_name : new_name\n","\n","# you can change the names of indeces by using 'index =' instead of 'columns =' \n","\n","# Note the 'inplace' argument! It can be either True or False (default is False)\n","# It specifies whether to return a new DataFrame. If True then value of copy is ignored.\n","\n","df.rename(columns = {'col1' : 'column_1',\n","                     'col2' : 'column_2'},\n","          inplace = True) # old_name : new_name\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8hlw_kXtk5w"},"source":["# Dropping the variables (or rows)\n","\n","df.drop(labels = ['col3', 'col4'], axis = 1, inplace = True)\n","\n","# axis can be 0 or 1, default 0\n","# Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAWbzu0AubZg"},"source":["# Replacing values in a dataframe using pandas .replace() method\n","\n","df.replace(to_replace = [1,2,3], value = [1000, 2000, 3000], inplace = True)\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yf2BT7PTOdAy"},"source":["---\n","\n","# **3. Frequency tables and crosstabs**\n","\n","<figure>\n","<left>\n","<img src=https://miro.medium.com/max/481/1*n_ms1q5YoHAQXXUIfeADKQ.png  width=\"450\">\n","</figure>"]},{"cell_type":"code","metadata":{"id":"lnBPCsn8LjWn"},"source":["# Let's get the dataset first!\n","\n","# Don't forget that your pathway to file will be different from mine\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Intro_to_python/Day_3/pokemon.csv')\n","\n","df.head()\n","\n","# Data source: https://gist.github.com/armgilles/194bcff35001e7eb53a2a8b441e8b2c6\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIVyYeAnMOqF"},"source":["df.shape # dimensions of the dataset\n","\n","df.info()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yT1CkCuzWdGL"},"source":["## **Frequency tables**"]},{"cell_type":"code","metadata":{"id":"yS8mAUFJMbZL"},"source":["# Let's first get the frequency table for the 'Type 1' variable.\n","# We can use pandas .value_counts() method for this\n","\n","df['Type 1'].value_counts() # sorts in descending order by default\n","\n","df['Type 1'].value_counts(ascending = True) # sort in ascending orders\n","\n","df['Type 1'].value_counts(sort = False) # don't sort by frequency\n","\n","df['Type 1'].value_counts(normalize = True) # get proportions instead of frequencies\n","\n","df['Type 1'].value_counts(normalize = True).round(2) * 100 # round proportions to two decimals and multiply by 100 to get percentage\n","\n","(df['Type 1'].value_counts(normalize = True).round(2) * 100).sum() # 100% indeed\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lM93QFTPjFD"},"source":["# If you pass more than 1 variable to .value_counts()\n","# you get how many observations are there in each combination of values\n","\n","# Note that if you pass more than variable, they should go as list i.e. ['Type 1', 'Legendary']\n","\n","df[['Type 1', 'Legendary']].value_counts()\n","\n","# Same number of observations, 800 pokemons in total\n","\n","df['Type 1'].value_counts().sum() == df[['Type 1', 'Legendary']].value_counts().sum()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loqcuwI_QAIH"},"source":["# Note that the strength of Python and any programming language basically is that instead of\n","# writing same lines of code for repetetive oeprations i.e. showing frequency tables\n","# for more than one variable, you can optimize it and make Python do it for you\n","\n","# We don't cover it in this course because it's a more advanced stuff, but just for you to know\n","# that if you want to show frequency tables for two variables, instead of writing:\n","\n","# df['Type 1'].value_counts()\n","# df['Legendary'].value_counts()\n","\n","# You can use either .apply() method and apply value_counts() to\n","# two or more variables in the following wat:\n","\n","df[['Type 1', 'Legendary']].apply(pd.Series.value_counts)\n","\n","# Or use a for loop, in which for each variable you can consequently print out:\n","# A line with variable's name\n","# A frequency table\n","# A line break\n","\n","for variable in df[['Type 1', 'Legendary']]:\n","  print(f'Frequency table for {variable} variable')\n","  print(df[variable].value_counts())\n","  print('\\n') # \\n denotes a line break in Python\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXIVSV8yWmYG"},"source":["## **Crosstabs**"]},{"cell_type":"code","metadata":{"id":"lnE9IqsCOIdy"},"source":["# You can get a crosstab in pandas via .crosstab() method\n","\n","# Crosstab of Generation and Legendary variables\n","\n","pd.crosstab(df['Generation'], df['Legendary'])\n","\n","pd.crosstab(df['Generation'], df['Legendary'], margins = True) # Add row/column margins (subtotals)\n","\n","pd.crosstab(df['Generation'], df['Legendary'],\n","            margins = True, normalize = 'index') # row proportions, assuming that Generation affects Legendary status\n","\n","pd.crosstab(df['Generation'], df['Legendary'],\n","            margins = True, normalize = 'columns') # column proportions, assuming that Legendary status affects Pokemon's generation\n","\n","# Round the numbers and multiply by 100\n","\n","# Would you say that Pokemon's generation affects its Legendary status?\n","\n","pd.crosstab(df['Generation'], df['Legendary'],\n","            margins = True, normalize = 'index').round(2) * 100\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvD-Xdi_XKnr"},"source":["---\n","\n","# **3. Descriptive statistics for numeric variables**\n"]},{"cell_type":"code","metadata":{"id":"LUz-elPitiEE"},"source":["# Let's ask pandas to round up all numbers to two decimals\n","\n","pd.set_option(\"display.precision\", 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qT8DeytrWwBO"},"source":["# If you run .describe() method on the entire dataframe, it will pick out numeric variables\n","# and provide following statistics: count, mean, std, min, max, 25% and 75% percentile, and median (50% percentile)\n","\n","df.describe()\n","\n","# You can transpose the matrix if you wish\n","\n","df.describe().transpose()\n","\n","# Works on separate columns too:\n","\n","df['HP'].describe()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RR0GOrC7YuI_"},"source":["# This is how you can get all these statistics separately:\n","\n","df['HP'].count() # counts non-missing cells\n","\n","df['HP'].mean() # mean value\n","\n","df['HP'].std() # standard deviation\n","\n","df['HP'].min() # minimum value\n","\n","df['HP'].max() # maximum value\n","\n","df['HP'].median() # median value\n","\n","df['HP'].quantile(q = [0.25, 0.75]) # 25% and 75% quantiles\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZkeEG4ZZ4lZ"},"source":["# Works for more than one variable too\n","\n","df[['Attack', 'Defense']].mean()\n","\n","# And for more than one statistic as well, but in this case you need to use .agg() method\n","# Statistics are supplied as a list and each one of them should be in speech marks\n","\n","df[['Attack', 'Defense']].agg(['count', 'mean', 'std', 'median'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f430WHxpcbMT"},"source":["---\n","\n","# **4. Aggregated statistics**\n","\n","<figure>\n","<left>\n","<img src=https://miro.medium.com/max/1400/0*XVlrOuSBNKwIZpPj.png width=\"500\">\n","</figure>\n","\n","**[Image source](https://towardsdatascience.com/7-pandas-functions-that-i-use-the-most-b83ddbaf53bf)**"]},{"cell_type":"code","metadata":{"id":"WzfXIQZCbK5s"},"source":["# Aggregated analysis implies that you get some statistic (e.g. mean or median) of your main variable\n","# separately for groups of observations defined by some other variable.\n","\n","# (also known as Split-Apply-Combine technique)\n","\n","# Your main variable should continuous, whereas grouping variable - categorical. \n","\n","# For example:\n","\n","# mean income for men and women\n","# median level of life satisfaction for young, middle-aged, and elderly people\n","# 25% and 75% percentiles of anxiety scale for 1st, 2nd, and 3rd-year students\n","\n","# The process of getting aggregated statistics requires two steps:\n","# You first group your data via .groupby() method,\n","# and then get aggregated values\n","\n","# Getting the mean HP level for legendary and non-legendary pokemons\n","\n","df.groupby('Legendary')['HP'].mean()\n","\n","# Getting the median Attack level per Pokemon generation\n","\n","df.groupby('Generation')['Attack'].median()\n","\n","# You can group by more than one variable:\n","\n","df.groupby(['Generation', 'Legendary'])['Attack'].median()\n","\n","# And get statistic for more than one outcome variable\n","\n","df.groupby(['Generation', 'Legendary'])[['Attack', 'Defense']].median()\n","\n","# It is also possible to get more than one statistic simultaneously,\n","# but then they need to be wrapper up in the .agg() method\n","\n","# Let say that for each generation of Pokemons, I want to know\n","# the mean, median, and standard deviation of their HP, Attack, and Defense points\n","\n","df.groupby('Generation')[['HP', 'Attack', 'Defense']].agg(['mean', 'median', 'std'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OK7nxkvqptC"},"source":["## **Exercise**\n","\n","Alright, it's time to practice!\n"]},{"cell_type":"code","metadata":{"id":"mFvI66ELk3fv"},"source":["# Let's get the mtcars dataset first\n","\n","# Don't forget that your pathway to file will be different from mine\n","mtcars = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Intro_to_python/Day_2/mtcars.csv')\n","\n","mtcars.head(15)\n","\n","# Motor Trend Car Road Tests data\n","# The data was extracted from the 1974 Motor Trend US magazine,\n","# and comprises fuel consumption and 10 aspects of automobile design and performance\n","# for 32 automobiles (1973–74 models).\n","\n","# mpg - Miles/(US) gallon\n","# cyl - Number of cylinders\n","# disp - Displacement (cu.in.)\n","# hp - Gross horsepower\n","# drat - Rear axle ratio\n","# wt - Weight (1000 lbs)\n","# qsec - 1/4 mile time\n","# vs - Engine (0 = V-shaped, 1 = straight)\n","# am - Transmission (0 = automatic, 1 = manual)\n","# gear - Number of forward gears\n","# carb - Number of carburetors\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFhg2zJCDoOE"},"source":["Using the `mtcars` dataset, please answer the following questions:\n","\n","+ How many cars have **8 cylinders**?\n","+ Among all cars, what is the proportion of those having **4 gears**?\n","+ Among all cars, what is the proportion of those having **more than 1 carburetor**?\n","+ Among cars with **automatic transmission**, how many of them have a **straight engine**?\n","+ Among cars with **6 cylinders**, what is the proportion of those having **gross horsepower of higher than 150**?\n","+ Among all cars, what is the **mean 1/4 mile time**?\n","+ If we take only those cars that **weight more than 75% of other cars** and have a **V-shaped engine**, what would be their **mean 1/4 mile time**?\n","+ Get the **mean value of miles per gallon** for cars with different **number of carburetors**. Which group has the highest average mileage?\n","+ Get the **mean and median values of displacement** for cars with different **number of cylinders**. For which group/groups, median value is higher than the mean? \n","+ Finally, say we're interested in comparing **Mercedes vs all other cars**. Is it true, that for Mercedes the **mean 1/4 mile time** is always higher than for other cars, regardless of how many **gears** they have?"]},{"cell_type":"code","metadata":{"id":"vWdaXgr3OeAU"},"source":["mtcars.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5zyRRQREl50"},"source":["# How many cars have 8 cylinders?\n","\n","mtcars['cyl'].value_counts()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49r0xmWqE_HP"},"source":["# Among all cars, what is the proportion of those having 4 gears?\n","\n","mtcars['gear'].value_counts(normalize = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfzqADveEmD8"},"source":["# Among all cars, what is the proportion of those having more than 1 carburetor?\n","\n","# Approach #1\n","\n","mtcars['carb_rec'] = np.where(mtcars['carb'] > 1, True, False) # creating a new variable for the condition\n","\n","mtcars['carb_rec'].value_counts(normalize = True) # getting its frequency table\n","\n","mtcars.drop(['carb_rec'], axis = 1, inplace = True) # dropping the variable\n","\n","# Approach #2\n","\n","(mtcars['carb'] > 1).sum() / len(mtcars['carb']) # how many cars have more than 1 carb / how many cars are there in total\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWIFityhHmWk"},"source":["# Among cars with automatic transmission, how many of them have a straight engine?\n","\n","pd.crosstab(mtcars['am'], mtcars['vs'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YE5lbnjLIMl8"},"source":["# Among cars with 6 cylinders, what is the proportion of those having gross horsepower of higher than 150?\n","\n","# Approach #1\n","\n","mtcars['hp_rec'] = np.where(mtcars['hp'] > 150, True, False) # creating a new variable for the condition\n","\n","\n","pd.crosstab(mtcars['cyl'], mtcars['hp_rec'], normalize = 'index') # crosstab with proportions by index (cyl variable)\n","\n","# Approach #2\n","\n","((mtcars['cyl'] == 6) & (mtcars['hp'] > 150)).sum() / (mtcars['cyl'] == 6).sum()\n","# how many cars satisfy the condition / how many cars are there in total\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pRH9sEiLFyx"},"source":["# Among all cars, what is the mean 1/4 mile time?\n","\n","mtcars['qsec'].mean()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gx5FYRCFMQ7v"},"source":["# If we take only those cars that weight more than 75% of other cars and have a V-shaped engine,\n","# what would be their mean 1/4 mile time?\n","\n","# Let's first see what is the weight value of a 3rd quartile (75%)\n","\n","weight_75 = mtcars['wt'].quantile(q = 0.75)\n","\n","weight_75\n","\n","# Now let's create a new variable testing whether car weights more than the 75% quartile and has V-shaped engine\n","\n","mtcars['cond'] = np.where((mtcars['wt'] > weight_75) & (mtcars['vs'] == 0), 'Satisfy', 'Does not satisfy')\n","\n","mtcars['cond'].value_counts()\n","\n","# Now select only those cars that satisfy the condition and calculate their mean 1/4 mile time\n","\n","mtcars.loc[mtcars['cond'] == 'Satisfy', 'qsec'].mean()\n","\n","mtcars.drop(['cond'], axis = 1, inplace = True)\n","\n","# Same but all in one command\n","\n","mtcars.loc[(mtcars['wt'] > weight_75) & (mtcars['vs'] == 0), 'qsec'].mean()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaiudmJnSC6N"},"source":["# Get the mean value of miles per gallon for cars with different number of carburetors. Which group has the highest mileage?\n","\n","mtcars.groupby('carb')['mpg'].mean()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkkDuupiTEYp"},"source":["# Get the mean and median values of displacement for cars with different number of cylinders.\n","# For which group/groups, median value is higher than the mean? \n","\n","mtcars.groupby('cyl')['disp'].agg(['mean', 'median'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2toSoKTdUnoD"},"source":["# Finally, say we're interested in comparing Mercedes vs all other cars.\n","# Is it true, that for Mercedes the mean 1/4 mile time is always higher than for other cars, regardless of how many gears they have?\n","\n","# Run this line to create a new binary variable for Mercedes\n","\n","mtcars['is_merc'] = np.where(mtcars['model'].str.contains('Merc'), True, False)\n","\n","mtcars.groupby(['is_merc', 'gear'])['qsec'].mean()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Il8v38YXWkin"},"source":["# **That's the end of Day 3!**\n"]}]}