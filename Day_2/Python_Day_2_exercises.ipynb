{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python_Day_2_exercises.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"157p2dupM6EhY2u-nrj_ffkQuqPEWuSRS","authorship_tag":"ABX9TyMSfgwOU+h3P6mwVDX9Lgv0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EWB457PFT4J2"},"source":["# **Introduction to Python. Day 2**\n","\n","## *Dr Kirils Makarovs*\n","\n","## *k.makarovs@exeter.ac.uk*\n","\n","## *University of Exeter Q-Step Centre*\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"6b_C8WzNqV4z"},"source":["# **Welcome to Day 2!**"]},{"cell_type":"markdown","metadata":{"id":"ZSbdhnpgS34g"},"source":["## **By now, you should be familiar with:**\n","\n","+ The overall workflow of Jupyter Notebooks in Google Colab\n","+ The basics of Python syntax and operations with lists\n"]},{"cell_type":"markdown","metadata":{"id":"DmD95g7Na2wJ"},"source":["## **Today, we are going to look at:**\n","\n","+ How to read in external datasets and create your own ones\n","+ How to navigate datasets - subsetting, accessing rows/columns\n","+ Operations with variables i.e. recoding, creating new variables\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlyQaFb3PFbh"},"source":["# **1. Preparing to work in Python**"]},{"cell_type":"code","metadata":{"id":"Gi-tODR_pzmZ"},"source":["# Import the necessary libraries\n","\n","import pandas as pd # data analysis and management library\n","import numpy as np # multi-dimensional arrays\n","import math # library with math-related commands like square root, etc.\n","import random # random number generator via random.sample()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XOVOH_1qrIB"},"source":["# Mount your Google Drive\n","\n","# Mounting your Google Drive will enable you to access files from Drive in Google Colab e.g. datasets, notebooks, etc.\n","\n","from google.colab import drive\n","\n","# This will prompt for authorization. Enter your authorisation code and rerun the cell\n","\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yf2BT7PTOdAy"},"source":["---\n","\n","# **2. Pandas. Working with dataframes in Python**\n","\n","<figure>\n","<left>\n","<img src=https://miro.medium.com/max/481/1*n_ms1q5YoHAQXXUIfeADKQ.png  width=\"450\">\n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"qkKg5CCAPLdY"},"source":["## **Loading dataframes from external sources**\n","\n","With *Pandas*, you can open datasets that are stored in a great variety of formats\n","\n","(just start typeing `pd.read_` in a code cell and you'll see all the possible options)\n","\n","Here is a list of most common types of data and commands to open them\n","\n","| Data format | Explanation | Command\n","| ------- | -------- | ---\n","| .csv | Comma-separated values | `pd.read_csv()`\n","| .xls / .xlsx | Excel spreadsheet | `pd.read_excel()`\n","| .dta | STATA Data file format | `pd.read_stata()`\n","| .sav | SPSS Data file format | `pd.read_spss()`\n","\n","This is how a typical dataset looks like:\n","\n","<figure>\n","<left>\n","<img src=https://media.geeksforgeeks.org/wp-content/uploads/finallpandas.png width=\"550\">\n","</figure>\n","\n","**[Image source](https://www.geeksforgeeks.org/python-pandas-dataframe/)**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"T4ooguvNbjUs"},"source":["# Here is an example of how to open a .csv dataframe in Python using Pandas library\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Intro_to_python/Day_2/mtcars.csv')\n","# Note that you need to mount your Google Drive first! (see above)\n","# And it's likely that your pathway to file will be different from mine\n","\n","df.head(10)\n","\n","# to see explanation and additional arguments for this and other commands run 'pd.your_command_here?'\n","# E.g. pd.read_csv?\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"etU4CeDue7Lo"},"source":["## **Generating dataframes manually**\n","\n","You can also generate your own data from lists, arrays and other types of data in Python via `pd.DataFrame()` command"]},{"cell_type":"code","metadata":{"id":"HbWfHvegBU-A"},"source":["# Generating a dataset from a numpy array, in which each element is a list\n","\n","df = pd.DataFrame(data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n","                  columns = ['a', 'b', 'c'])\n","\n","df\n","\n","# Generating the very same dataset from a dictionary\n","# {'column_name_1' : [column_data_1],\n","#  'column_name_2' : [column_data_2],\n","#  'column_data_3' : [column_data_3]}\n","\n","df = pd.DataFrame(data = {'a' : [1, 2, 3],\n","                          'b' : [4, 5, 6],\n","                          'c' : [7, 8, 9]})\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMnj5Q1tuBHk"},"source":["## **Exercise 1**\n","\n","Look at this screenshot of a dataset below that I created using `pd.DataFrame()` command.\n","\n","You will now be asked to replicate it! More instruction in the code cell below.\n","\n","<figure>\n","<left>\n","<img src=https://i.ibb.co/M6GytC2/data.png width=\"500\">\n","</figure>\n"]},{"cell_type":"code","metadata":{"id":"SvEb630Gp3Hs"},"source":["# The dataset above consists of 15 rows and 6 columns (variables), and each column follows a certain pattern.\n","# Identify it and try to replicate!\n","# Recall all you know about lists and how you can concatenate and multiplicate them,\n","# and try to reproduce this very dataset via pd.DataFrame() command.\n","# (I suggest using the dictionary approach to creating dataset)\n","# Note that var_1 consists of 15 random values taken from the range of 10 to 1000, so your values won't be exactly as mine are\n","# For all other columns - it is possible to replicate them fully!\n","\n","# (Please don't try to manually define all the values in each column - the main reason we're learning coding is to save ourselves some time and nerves!)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrYO319Yvdoq"},"source":["---\n","\n","# **3. Getting to know a dataframe in Pandas**\n","\n"]},{"cell_type":"code","metadata":{"id":"8m6hwEdnXPCz"},"source":["# Let's create a dataset with the following columns:\n","\n","# Name of a staff\n","# Life satisfaction on the scale from 0 to 10\n","# Whether they were in the office last Tuesday\n","# Job type\n","# Their body temperature\n","\n","# I additionaly set indeces (i.e. row names) with the index argument.\n","\n","df = pd.DataFrame(data = {'name' : ['Michael', 'Dwight', 'Jim', 'Pam', 'Erin', 'Kevin', 'Andy', 'Angela'],\n","                          'life_satisfaction' : [5, 9, 7, 7, 8, 5, 10, 4],\n","                          'tuesday' : [True, False, False, False, True, True, True, True],\n","                          'job' : ['manager', 'sales', 'sales', 'sales', 'receptionist', 'accounting', 'sales', 'accounting'],\n","                          'temperature' : [36.8, 37.1, 36.1, 36.6, 38.2, 39.1, 36.5, 36.9]\n","                          },\n","                  index = ['MS', 'DS', 'JH', 'PB', 'EH', 'KM', 'AB', 'AM']\n","                  )\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeLupr7heX8q"},"source":["# Some helpful commands to get to know the dataset\n","\n","type(df) # object type - pandas.core.frame.DataFrame\n","\n","df\n","\n","df.shape # number of rows and columns\n","\n","df.columns # column names\n","\n","df.index # indeces\n","\n","df.info() # summary of the variables in the dataset\n","# Dtype column shows what type of variable it is - we'll talk about it later\n","\n","df.head(10) # get the top 5 rows of the dataset\n","\n","df.tail() # get the last 5 rows of the dataset\n","\n","df.describe() # picks out only numerical variables (Dtype int64 or float64)\n","# and shows basic descriptive statistics\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LUz-elPitiEE"},"source":["# If you want all numbers to be rounded up to two decimals, run this line:\n","\n","pd.set_option(\"display.precision\", 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zaK2pECqB_A"},"source":["\n","---\n","\n","# **4. Subsetting dataframes via `.loc[]` and `.iloc[]` methods**"]},{"cell_type":"markdown","metadata":{"id":"S1gfGTY6lLM1"},"source":["| Command | Description |\n","| ------ | ----------- |\n","| `.iloc[]`   | position-based subsetting |\n","| `.loc[]` | label-based subsetting |"]},{"cell_type":"markdown","metadata":{"id":"YzGX-NdnClu1"},"source":["## **Using `.iloc[]` to navigate a dataframe by row and column numbers**"]},{"cell_type":"code","metadata":{"id":"IDIKO54c54tR"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYCOK3rejAio"},"source":["# Selecting various columns from the dataframe\n","\n","df.iloc[:, 0] # select first column (remember that Python starts counting from 0!)\n","\n","# Note that when you pick a single column, you get as a Series rather than a DataFrame (check type(df.iloc[:, 0]))\n","# If you want it to be a DataFrame with a single column, provide the number of column in [], like this: df.iloc[:, [0]]\n","# This only applies to those cases when you want to pick a single column\n","\n","df.iloc[:, 1:3] # select 2nd and 3rd columns\n","\n","df.iloc[:, -2:] # select last 2 columns \n","\n","df.iloc[:, :-1] # select all columns except the last one\n","\n","df.iloc[:, [0, 1, 4]] # select the 1st, 2nd, and 5th columns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_iKlMTbkOHW"},"source":["# Same goes with rows\n","\n","df.iloc[0, :] # select first row and all columns. Also try df.iloc[[0], :]\n","\n","df.iloc[[0], :]\n","\n","df.iloc[:4, :] # select first 4 rows\n","\n","df.iloc[-5:, :] # select last 5 rows \n","\n","df.iloc[:-3, :] # select all rows except last 3\n","\n","df.iloc[[0, 3, 7], :] # select 1st, 4th, and 8th rows\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWbkaO07lbUz"},"source":["# You can combine row and column selection with .iloc[]\n","\n","df.iloc[0:6, 1:4] # select first 5 rows and columns from 2 to 4\n","\n","df.iloc[[1, 5, 7], [0, 2, 4]] # 2nd, 6th, and 8th rows and 1st, 3rd, and 5th columns\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hhzud67qudzy"},"source":["## **Using `.loc[]` to navigate a dataframe by row and column names**"]},{"cell_type":"code","metadata":{"id":"Dn0VLwAby2uG"},"source":["# Generally, .loc[] method is more helpful than the .iloc[] one\n","# as you usually want to pick variables (and, less commonly, rows) by their names\n","# rather than their position in the dataframe\n","\n","df.loc[:, 'name'] # select the variable of name. Also try df.loc[:, ['name']]\n","\n","# When selecting columns, you can simply use: df['name'] or df[['name']]\n","\n","df.loc[:, ['name', 'tuesday', 'temperature']] # selecting three variables\n","\n","df[['name', 'tuesday', 'temperature']] # selecting three variables\n","\n","df.drop(['name'], axis = 1) # keep all variables except name.\n","# Axis = 1 means that .drop() method will look for 'name' among column names\n","# Axis = 0 would imply search among row names\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NndtfEJ9zFO2"},"source":["# Selecting rows by their indeces - same principle\n","\n","df.loc[['MS', 'DS', 'AM'], :] # three rows, all variables\n","\n","df.drop(['AM'], axis = 0) # keep all rows except AM\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJekJyjKpAZI"},"source":["# Finally you can combine row and column selection via .loc[]\n","\n","df.loc[['MS', 'EH'], ['life_satisfaction', 'temperature']]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OK7nxkvqptC"},"source":["## **Exercise 2**\n","\n","Alright, now you will practice what you've learned!\n"]},{"cell_type":"code","metadata":{"id":"GrXdERwGHjOR"},"source":["# Using .iloc[] and .loc[] methods, please:\n","\n"," # select first 4 rows and all columns\n","\n"," # select 2 last columns and all rows\n","\n"," # select rows 2, 5, and 7, and all columns except the 3rd one\n","\n","df.columns[2] # this is how you can see which column goes under the number 2 (that is, 3rd column in the dataframe)\n","\n"," # select columns of job and temperature\n","\n"," # select rows that are labelled as KM, AB, and MS\n","\n","# Now, try to select only those rows whose labels start with A, and those columns whose name start with t\n","# First, remember how you can access the names of all columns and rows in Pandas dataframe\n","# Then apply .str.startswith('') method on it and put 'A' and 't' in round brackets respectively\n","# Now wrap it into the .loc[] method and you should be able to get a correct result!\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sT0mNGUy4VqX"},"source":["---\n","\n","# **5. Subsetting dataframes based on the values of variables**"]},{"cell_type":"code","metadata":{"id":"0Kz6rbp5RWL1"},"source":["# Let's get the dataset\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5mBjRBu4eJs"},"source":["# This involves working with .loc[] method and using logical statements\n","\n","# Say we need to select only those people who work in sales\n","# This is the same as saying that we need to keep all columns\n","# and select only those rows (people) who have 'sales' in job variable\n","\n","# First, try running this:\n","\n","df['job'] == 'sales'\n","\n","# Each row of the dataset is tested whether its value of job variable is equal to 'sales'\n","# As a result, you get a Series of True or False values, and it's length is equal\n","# to the number of rows in the dataset\n","\n","len(df['job'] == 'sales') == df.shape[0] # True\n","\n","# Now if you plug this into .loc[] method, you will be able to select\n","# only those rows, that got True value i.e. they work in sales\n","\n","df.loc[df['job'] == 'sales', :] # select only those who work in sales and keep all columns\n","\n","# For short, this can also be done as df.loc[df['job'] == 'sales']\n","\n","# Or even shorter: df[df['job'] == 'sales']\n","\n","# You can test more than one condition at the same time, but then each one of them\n","# should be put in round brackets and concatenated either with & or |\n","\n","# & in Pandas means AND\n","# | in Pandas means OR (see image below)\n","\n","# So, say we want to keep only those people who work in sales\n","# AND whose level of life satisfaction is above 5\n","\n","# Here is how you can test these two condition\n","\n","(df['job'] == 'sales') & (df['life_satisfaction'] > 5)\n","\n","# And this is how you use them with .loc[]\n","\n","df.loc[(df['job'] == 'sales') & (df['life_satisfaction'] > 5)]\n","\n","# Selecting those who are either manager or accountant\n","\n","df.loc[(df['job'] == 'manager') | (df['job'] == 'accounting')]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcQ6eaHMbKjh"},"source":["<figure>\n","<left>\n","<img src=https://www.lotame.com/wp-content/uploads/2016/07/BooleanLogic_NR.jpg  width=\"500\">\n","</figure>"]},{"cell_type":"code","metadata":{"id":"DsuVV6XDd21I"},"source":["# You can use .isin() method instead of multiple OR conditions if you want to select more than one category from a single variable\n","\n","# Same as a last example above, but via .isin() method\n","\n","df.loc[df['job'].isin(['manager', 'accounting'])]\n","\n","# Shorter:\n","\n","df[df['job'].isin(['manager', 'accounting'])]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPSAh7MMfAvf"},"source":["# You can filter out boolean variables - those that get only True or False values - in the following way:\n","\n","# Keep only those people that have True in tuesday variable\n","\n","# This is the most explicit option:\n","\n","df.loc[df['tuesday'] == True]\n","\n","# These options also work:\n","\n","df[df['tuesday'] == True]\n","\n","df[df['tuesday']]\n","\n","# If you want to keep those who have False in a boolean variable:\n","\n","df.loc[df['tuesday'] != True] # same as '== False'\n","\n","df[df['tuesday'] != True]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGHkviD4itPl"},"source":["## **Exercise 3**\n","\n","Alright, time to practice!\n","\n","*Please select the following subsets of the `df` dataframe:*\n","\n","> 1. people, whose `temperature` is below or equal to 36.6\n","> 2. people, who **do not** work in sales\n","> 3. people, whose life satisfaction is above 7 **or** who were in on Tuesday\n","> 4. people, whose life satisfaction is above the median, **and** the temperature is above the mean\n","> 5. Michael, Jim, and Pam, and keep only `life_satisfaction` and `temperature` variables\n","\n","*(Feel free to create a new code cell per each task so you could clearly see the output dataset)*"]},{"cell_type":"code","metadata":{"id":"orWTt2Q1W-99"},"source":["# 1. People, whose temperature is below 36.6\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NaQnxHEXUPM"},"source":["# 2. People, who do not work in sales\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDKe6klbXiEl"},"source":["# 3. People, whose life satisfaction is above 7 or who were in on Tuesday\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCwenKkdYLKC"},"source":["# 4. People, whose life satisfaction is above the median, and the temperature is above the mean\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEmWlFzMY4On"},"source":["# 5. Michael, Jim, and Pam, and keep only life_satisfaction and temperature variables\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wARdRKpuZ-0U"},"source":["---\n","\n","# **6. Creating new variables in a dataframe**"]},{"cell_type":"markdown","metadata":{"id":"B3VhFzokqnqY"},"source":["## **Adding new variables manually**"]},{"cell_type":"code","metadata":{"id":"Yu9hSduOay2v"},"source":["# When creating a new variable, the dataframe is automatically updated\n","\n","df['random_column'] = 'random_value'\n","\n","df['true_or_false'] = True\n","\n","df['id_number'] = np.arange(start = 1, stop = df.shape[0] + 1, step = 1) # 1, 2, 3, 4, 5, 6, 7, 8\n","\n","df\n","\n","# When creating a variable manually, make sure that its length is the same as a number of rows in a dataframe\n","\n","# df['weird_numbers'] = [17, 21] # ValueError: Length of values (2) does not match length of index (8)\n","\n","df['weird_numbers'] = [17, 21] * 4 # This one works\n","\n","df\n","\n","# Drop useless variables\n","\n","df.drop(['random_column', 'true_or_false', 'weird_numbers', 'id_number'], axis = 1, inplace = True)\n","\n","# axis = 1 means searching for these names in column names (axis = 0 would search in row names)\n","\n","# Note the inplace = True argument\n","# Its default value is False\n","# If False, return a copy. Otherwise, do operation inplace and return None.\n","\n","# If you want to create a copy of a dataset without some of the variables, keep inplace = False (default), and run something like:\n","# df_2 = df.drop(['random_column', 'true_or_false', 'weird_numbers'], axis = 1)\n","\n","# 'inplace' argument applies to many of the pandas methods and functions, so keep an eye on the documentation!\n","\n","# Due to time constraints, in this course we don't cover merging two or more dataframes into one,\n","# or adding new values by key (i.e. by row index)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1VW1tKvpdTFk"},"source":["## **Creating new variables based on the values of existing variables**"]},{"cell_type":"code","metadata":{"id":"iLaFyXPvthFV"},"source":["# Let me add two new variables called income_year_1, and income_year_2\n","\n","# Derive 8 random values from the normal distribution which has a mean value of 35000 and sd of 10000,\n","# and then round up the values up to 1 decimal\n","\n","df['income_year_1'] = np.random.normal(35000, 10000, 8).round(1)\n","\n","df['income_year_2'] = np.random.normal(35000, 10000, 8).round(1)\n","\n","df\n","\n","# Variable of total income\n","\n","df['total_income'] = df['income_year_1'] + df['income_year_2']\n","\n","df\n","\n","# Less manual way\n","# df['total_income_2'] = df[['income_year_1', 'income_year_2']].sum(axis = 1)\n","\n","# Variable of mean income\n","\n","df['mean_income'] = df[['income_year_1', 'income_year_2']].mean(axis = 1)\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYCE9gmSeE0k"},"source":["### **Using `np.where()` to test a single if-else condition**\n","\n","`np.where()` has the following structure: *`(logical condition, value of True, value if False)`*"]},{"cell_type":"code","metadata":{"id":"4rGfmnIRfXlV"},"source":["# Creating a new variable called 'sales' that will have True for everyone who works in sales,\n","# and False for others\n","\n","df['sales'] = np.where(df['job'] == 'sales', True, False)\n","\n","df\n","\n","# Creating a new variable called 'life_satisfaction_binary' that will have 'High LS' value\n","# for everyone whose LS is above or equals 5, and 'Low LS' for others\n","\n","df['ls_binary'] = np.where(df['life_satisfaction'] >= 5, 'High', 'Low')\n","\n","# Creating a new variable called 'satisfied_and_healthy' that will have True value\n","# for everyone who's got LS value higher than the mean office value AND whose body temperature is strictly 36.6\n","\n","df['satisfied_and_healthy'] = np.where((df['life_satisfaction'] > df['life_satisfaction'].mean()) & (df['temperature'] == 36.6), True, False)\n","\n","(df['life_satisfaction'] > df['life_satisfaction'].mean()) & (df['temperature'] == 36.6)\n","\n","# Creating a new variable called 'is_rich' that will have 'YES' value\n","# for everyone whose total income is above the average total income in the office, and missing value for all others\n","\n","# np.nan - Not A Number - the most common type of missings in dataframes \n","\n","df['is_rich'] = np.where(df['total_income'] > df['total_income'].mean(), 'YES', np.nan)\n","\n","df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZcBxZI-C-kU"},"source":["## **Exercise 4**\n","\n","Time to practice!\n","\n","*Please create the following variables in the `df` dataframe:*\n","\n","> 1. `need_hospital`, that gets the value `True` if `temperature` is above 38, and `False` for others\n","> 2. `income_comparison`, that gets the value `'Year 1'` if income in the first year is higher than in the second year, and the value `'Year 2'` if the opposite\n","> 3. `happy_people`, that gets the value `'super happy'` if it's Michael or anyone else with life satisfaction of 9 or 10, and `'not really'` for all others\n","\n","\n","*(Feel free to create a new code cell per each task so you could clearly see the output dataset)*"]},{"cell_type":"code","metadata":{"id":"3qqZZ3azF-0-"},"source":["# 1. `need_hospital`, that gets the value `True` if `temperature` is above 38, and `False` for others\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NvFciPd0F_CT"},"source":["# 2. `income_comparison`, that gets the value 'Year 1' if income in the first year is higher than in the second year,\n","# and the value 'Year 2' if the opposite\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gw5c3KXbF_MK"},"source":["# `happy_people`, that gets the value `'super happy'` if it's Michael or anyone else with life satisfaction of 9 or 10,\n","# and `'not really'` for all others\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xW-VnCYT_tZB"},"source":["### **Postscriptum: Using `np.select()` to test multiple if-else conditions**\n","\n","`np.select()` has the following structure: *`(list of logical condition, list of respective output values)`*"]},{"cell_type":"code","metadata":{"id":"DBaU-P_aAL1m"},"source":["# np.select() documentation available here:\n","# https://numpy.org/doc/stable/reference/generated/numpy.select.html\n","\n","# Say you want to create a new variable called ls_level and group employees by their level of life satisfaction into 3 distinct groups:\n","\n","# Low LS - for those who scored anything from 0 to 4\n","# Mid LS - for those who scored anything from 5 to 7\n","# High LS - for those who scored anything from 8 to 10\n","\n","# This is nothing more than asking Python to:\n","\n","# Assign value 'Low ls' to the variable ls_level if df['life_satisfaction'] <= 4\n","# Assign value 'Mid ls' to the variable ls_level if (df['life_satisfaction'] >= 5) & (df['life_satisfaction'] <= 7)\n","# Assign value 'High ls' to the variable ls_level if df['life_satisfaction'] >= 8\n","\n","# To use this idea in np.select(), we need to create two lists\n","\n","# List of conditions:\n","\n","conditions = [df['life_satisfaction'] <= 4,\n","              (df['life_satisfaction'] >= 5) & (df['life_satisfaction'] <= 7),\n","              df['life_satisfaction'] >= 8]\n","\n","# List of outcome values:\n","\n","outcomes = ['Low LS', 'Mid LS', 'High LS']\n","\n","# Now use np.select to create a new variable\n","\n","df['ls_level'] = np.select(conditions, outcomes)\n","\n","# Check the results:\n","\n","df[['life_satisfaction', 'ls_level']]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tLaGvBoCkN0"},"source":["# **That's the end of Day 2!**"]}]}